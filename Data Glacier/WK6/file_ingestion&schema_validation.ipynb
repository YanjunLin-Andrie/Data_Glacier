{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eedb22b2-64fe-457f-9e48-d03c08ed8557",
   "metadata": {},
   "source": [
    "## Week 6: File ingestion and schema validation\n",
    "\n",
    "\n",
    "Take any csv/text file of 2+ GB of your choice. --- (You can do this assignment on Google colab)\n",
    "\n",
    "Read the file ( Present approach of reading the file )\n",
    "\n",
    "Try different methods of file reading eg: Dask, Modin, Ray, pandas and present your findings in term of computational efficiency\n",
    "\n",
    "Perform basic validation on data columns : eg: remove special character, white spaces from the col name\n",
    "\n",
    "As you already know the schema hence create a YAML file and write the column name in YAML file. --define separator of read and write file, column name in YAML\n",
    "\n",
    "Validate number of columns and column name of ingested file with YAML.\n",
    "\n",
    "Write the file in pipe separated text file (|) in gz format.\n",
    "\n",
    "Create a summary of the file:\n",
    "\n",
    "Total number of rows,\n",
    "Total number of columns\n",
    "File size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac45aa91-2436-4f03-a40a-7848d1736485",
   "metadata": {},
   "source": [
    "---\n",
    "## File ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaef5b02-b520-404d-9b13-6ea49e00798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06046061-b39d-43c5-bafc-3d834f28dcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3488002253"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file size confirmation\n",
    "os.path.getsize('transactions_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a621e5c-aa66-4db5-920a-88a24d319921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 0.010052919387817383 seconds to read the csv file with Dask.\n"
     ]
    }
   ],
   "source": [
    "# read data with Dask\n",
    "from dask import dataframe as dd\n",
    "start_time = time.time()\n",
    "dask_df = dd.read_csv('transactions_train.csv')\n",
    "end_time = time.time()\n",
    "print(f'It took {end_time - start_time} seconds to read the csv file with Dask.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b4b0bef-8b4c-47dc-87ea-aa55db48b732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 37.013733863830566 seconds to read the csv file with Pandas.\n"
     ]
    }
   ],
   "source": [
    "# read data with Pandas\n",
    "import pandas as pd\n",
    "start_time = time.time()\n",
    "pd_df = pd.read_csv('transactions_train.csv')#, error_bad_lines=False)\n",
    "end_time = time.time()\n",
    "print(f'It took {end_time - start_time} seconds to read the csv file with Pandas.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c17dc4-2a9e-47aa-b7e9-38e53461f660",
   "metadata": {},
   "source": [
    "## Dask is more effecient reading the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5fffa19-7e72-4944-a71f-14b147aba46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 5 entries, t_dat to sales_channel_id\n",
      "dtypes: object(2), float64(1), int64(2)"
     ]
    }
   ],
   "source": [
    "# number of columns and data frame information\n",
    "dask_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3007c25-8860-4d3e-b1a5-79f296d1b069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28425882"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows\n",
    "len(dask_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f5b66e5-2544-4790-a56a-75e296bfea73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8d/m7gwzxq50lz5c45g511_v_vr0000gn/T/ipykernel_8189/2138726085.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  dask_df.columns=dask_df.columns.str.replace('[#,@,&]','')\n"
     ]
    }
   ],
   "source": [
    "# remove special character\n",
    "dask_df.columns=dask_df.columns.str.replace('[#,@,&]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d675c1f7-079c-44cf-9bb1-af352c0929da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove white space from columns\n",
    "dask_df.columns = dask_df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "655638cc-e1fc-4f03-892f-36ff1eca52bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['t_dat', 'customer_id', 'article_id', 'price', 'sales_channel_id'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column names\n",
    "data=dask_df.columns\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed49bdb-5bef-4184-ad58-71371df83fb9",
   "metadata": {},
   "source": [
    "---\n",
    "## Schema Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e50716ab-9583-4df5-92e5-892b2d483632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcc15b12-58f0-40fd-a18f-562b7455e0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utility.py\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.load(stream, Loader=yaml.Loader)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "def col_header_val(dask_df,table_config):\n",
    "    dask_df.columns = dask_df.columns.str.lower()\n",
    "    dask_df.columns = dask_df.columns.str.replace('[^\\w]','_',regex=True)\n",
    "    dask_df.columns = list(map(lambda x: x.strip('_'), list(dask_df.columns)))\n",
    "    dask_df.columns = list(map(lambda x: replacer(x,'_'), list(dask_df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    dask_df.columns =list(map(lambda x: x.lower(), list(dask_df.columns)))\n",
    "    dask_df = dask_df.reindex(sorted(dask_df.columns), axis=1)\n",
    "    if len(dask_df.columns) == len(expected_col) and list(expected_col)  == list(dask_df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(dask_df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(dask_df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {dask_df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a70bb952-b1a5-4260-961b-3c6824d71f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing tran.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile tran.yaml\n",
    "file_type: csv\n",
    "dataset_name: file\n",
    "file_name: transactions\n",
    "table_name: edsurv\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns: \n",
    "    - t_dat\n",
    "    - customer_id\n",
    "    - price\n",
    "    - sales_channel_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
